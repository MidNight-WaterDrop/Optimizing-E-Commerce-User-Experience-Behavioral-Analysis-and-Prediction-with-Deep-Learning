{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4975ef",
   "metadata": {
    "id": "7d4975ef"
   },
   "outputs": [],
   "source": [
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = \"C:/Users/ericw/OneDrive/桌面\"\n",
    "os.chdir(path)\n",
    "data = pd.read_csv(\"df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d3bb456",
   "metadata": {
    "id": "4d3bb456",
    "outputId": "9a3e5860-d548-4999-a12b-606b20f4043d"
   },
   "outputs": [],
   "source": [
    "# Adjusting the target variable\n",
    "data['y_binary'] = (data['product_action_pageview_purchase'] >= 1).astype(int)\n",
    "\n",
    "# Identifying feature types\n",
    "dense_features = ['product_action_event_remove']\n",
    "sparse_features = ['product_skus_hash', 'day_of_week', 'hour_of_first_interaction', 'hour_of_last_interaction']\n",
    "\n",
    "# Label encode sparse features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "\n",
    "# Normalize dense features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data[dense_features] = scaler.fit_transform(data[dense_features])\n",
    "\n",
    "# Prepare features for DeepCTR\n",
    "X = data[sparse_features + dense_features]\n",
    "y_binary = data['y_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89158680",
   "metadata": {
    "id": "89158680",
    "outputId": "695b708a-934e-4e43-841c-bf38ae714ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3802/3802 - 9s - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "Epoch 2/10\n",
      "3802/3802 - 8s - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0050 - val_accuracy: 0.9991\n",
      "Epoch 3/10\n",
      "3802/3802 - 8s - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0056 - val_accuracy: 0.9990\n",
      "Epoch 4/10\n",
      "3802/3802 - 8s - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9990\n",
      "Epoch 5/10\n",
      "3802/3802 - 8s - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0062 - val_accuracy: 0.9990\n",
      "Epoch 6/10\n",
      "3802/3802 - 8s - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0052 - val_accuracy: 0.9990\n",
      "Epoch 7/10\n",
      "3802/3802 - 8s - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0046 - val_accuracy: 0.9990\n",
      "Epoch 8/10\n",
      "3802/3802 - 10s - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0065 - val_accuracy: 0.9982\n",
      "Epoch 9/10\n",
      "3802/3802 - 9s - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 10/10\n",
      "3802/3802 - 8s - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0054 - val_accuracy: 0.9989\n",
      "1189/1189 [==============================] - 1s 1ms/step - loss: 0.0050 - accuracy: 0.9988\n",
      "\n",
      "Test loss: 0.00500574940815568\n",
      "Test accuracy: 0.9988262057304382\n"
     ]
    }
   ],
   "source": [
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the feature columns for DeepFM\n",
    "sparse_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(), embedding_dim=4)\n",
    "                          for i, feat in enumerate(sparse_features)]\n",
    "dense_feature_columns = [DenseFeat(feat, 1,)\n",
    "                         for feat in dense_features]\n",
    "\n",
    "feature_columns = sparse_feature_columns + dense_feature_columns\n",
    "feature_names = get_feature_names(feature_columns)\n",
    "\n",
    "# Convert the dataset into a format that can be fed into DeepFM\n",
    "train_model_input = {name: X_train[name] for name in feature_names}\n",
    "test_model_input = {name: X_test[name] for name in feature_names}\n",
    "\n",
    "# Build, compile, and train the model\n",
    "model = DeepFM(feature_columns, feature_columns, task='binary')\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_model_input, y_train, batch_size=256, epochs=10, verbose=2, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_result = model.evaluate(test_model_input, y_test, batch_size=256)\n",
    "print(\"\\nTest loss:\", eval_result[0])\n",
    "print(\"Test accuracy:\", eval_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5576d08c",
   "metadata": {
    "id": "5576d08c",
    "outputId": "5cdfbb01-33ab-4cf1-c2bd-ae1ec7c04012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[302152     85]\n",
      " [   272   1638]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    302237\n",
      "           1       0.95      0.86      0.90      1910\n",
      "\n",
      "    accuracy                           1.00    304147\n",
      "   macro avg       0.97      0.93      0.95    304147\n",
      "weighted avg       1.00      1.00      1.00    304147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred_probs = model.predict(test_model_input, batch_size=256)\n",
    "# Convert probabilities to binary predictions based on a 0.5 threshold\n",
    "y_pred = (y_pred_probs > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate precision, recall, F1-score, and support\n",
    "clf_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(clf_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82008215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "Epoch 1/10\n",
      "4753/4753 - 10s - loss: 0.0112 - accuracy: 0.9976\n",
      "Epoch 2/10\n",
      "4753/4753 - 10s - loss: 0.0035 - accuracy: 0.9994\n",
      "Epoch 3/10\n",
      "4753/4753 - 9s - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 4/10\n",
      "4753/4753 - 9s - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 5/10\n",
      "4753/4753 - 9s - loss: 0.0031 - accuracy: 0.9994\n",
      "Epoch 6/10\n",
      "4753/4753 - 9s - loss: 0.0031 - accuracy: 0.9994\n",
      "Epoch 7/10\n",
      "4753/4753 - 9s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 8/10\n",
      "4753/4753 - 9s - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "4753/4753 - 9s - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "4753/4753 - 9s - loss: 0.0024 - accuracy: 0.9994\n",
      "Fold 1 ROC-AUC: 0.9987549540497043\n",
      "Training on fold 2...\n",
      "Epoch 1/10\n",
      "4753/4753 - 11s - loss: 0.0115 - accuracy: 0.9977\n",
      "Epoch 2/10\n",
      "4753/4753 - 9s - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 3/10\n",
      "4753/4753 - 9s - loss: 0.0041 - accuracy: 0.9993\n",
      "Epoch 4/10\n",
      "4753/4753 - 9s - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 5/10\n",
      "4753/4753 - 9s - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 6/10\n",
      "4753/4753 - 9s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 7/10\n",
      "4753/4753 - 9s - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 8/10\n",
      "4753/4753 - 9s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "4753/4753 - 9s - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "4753/4753 - 9s - loss: 0.0023 - accuracy: 0.9994\n",
      "Fold 2 ROC-AUC: 0.9979426063886132\n",
      "Training on fold 3...\n",
      "Epoch 1/10\n",
      "4753/4753 - 10s - loss: 0.0121 - accuracy: 0.9976\n",
      "Epoch 2/10\n",
      "4753/4753 - 9s - loss: 0.0038 - accuracy: 0.9996\n",
      "Epoch 3/10\n",
      "4753/4753 - 9s - loss: 0.0042 - accuracy: 0.9992\n",
      "Epoch 4/10\n",
      "4753/4753 - 10s - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 5/10\n",
      "4753/4753 - 9s - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 6/10\n",
      "4753/4753 - 10s - loss: 0.0031 - accuracy: 0.9994\n",
      "Epoch 7/10\n",
      "4753/4753 - 10s - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 8/10\n",
      "4753/4753 - 10s - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "4753/4753 - 10s - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 10/10\n",
      "4753/4753 - 10s - loss: 0.0021 - accuracy: 0.9995\n",
      "Fold 3 ROC-AUC: 0.9970117040062232\n",
      "Training on fold 4...\n",
      "Epoch 1/10\n",
      "4753/4753 - 11s - loss: 0.0117 - accuracy: 0.9977\n",
      "Epoch 2/10\n",
      "4753/4753 - 10s - loss: 0.0035 - accuracy: 0.9994\n",
      "Epoch 3/10\n",
      "4753/4753 - 10s - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 4/10\n",
      "4753/4753 - 10s - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 5/10\n",
      "4753/4753 - 10s - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 6/10\n",
      "4753/4753 - 10s - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 7/10\n",
      "4753/4753 - 10s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 8/10\n",
      "4753/4753 - 10s - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "4753/4753 - 10s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "4753/4753 - 9s - loss: 0.0025 - accuracy: 0.9994\n",
      "Fold 4 ROC-AUC: 0.9974083355855179\n",
      "Training on fold 5...\n",
      "Epoch 1/10\n",
      "4753/4753 - 11s - loss: 0.0112 - accuracy: 0.9977\n",
      "Epoch 2/10\n",
      "4753/4753 - 9s - loss: 0.0033 - accuracy: 0.9995\n",
      "Epoch 3/10\n",
      "4753/4753 - 10s - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 4/10\n",
      "4753/4753 - 10s - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 5/10\n",
      "4753/4753 - 10s - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 6/10\n",
      "4753/4753 - 10s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 7/10\n",
      "4753/4753 - 9s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 8/10\n",
      "4753/4753 - 10s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "4753/4753 - 9s - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 10/10\n",
      "4753/4753 - 10s - loss: 0.0022 - accuracy: 0.9995\n",
      "Fold 5 ROC-AUC: 0.9960606359631341\n",
      "Mean ROC-AUC: 0.9974356471986386\n",
      "Standard Deviation of ROC-AUC: 0.00090207625397621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store results for each fold\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"Training on fold {fold+1}...\")\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    X_train_fold, y_train_fold = X.iloc[train_idx], y_binary.iloc[train_idx]\n",
    "    X_val_fold, y_val_fold = X.iloc[val_idx], y_binary.iloc[val_idx]\n",
    "    \n",
    "    # Prepare model input\n",
    "    train_model_input = {name: X_train_fold[name] for name in feature_names}\n",
    "    val_model_input = {name: X_val_fold[name] for name in feature_names}\n",
    "    \n",
    "    # Define the DeepFM model\n",
    "    model = DeepFM(feature_columns, feature_columns, task='binary')\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_model_input, y_train_fold, batch_size=256, epochs=10, verbose=2)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_fold = model.predict(val_model_input, batch_size=256)\n",
    "    \n",
    "    # Calculate the ROC-AUC score and append to the list\n",
    "    roc_auc = roc_auc_score(y_val_fold, y_pred_fold)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    print(f\"Fold {fold+1} ROC-AUC: {roc_auc}\")\n",
    "\n",
    "# Calculate the mean and standard deviation of the ROC-AUC scores\n",
    "mean_roc_auc = np.mean(roc_auc_scores)\n",
    "std_dev_roc_auc = np.std(roc_auc_scores)\n",
    "\n",
    "print(f\"Mean ROC-AUC: {mean_roc_auc}\")\n",
    "print(f\"Standard Deviation of ROC-AUC: {std_dev_roc_auc}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
