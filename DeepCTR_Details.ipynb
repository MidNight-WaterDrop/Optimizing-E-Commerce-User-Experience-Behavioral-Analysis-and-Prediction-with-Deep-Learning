{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4975ef",
   "metadata": {
    "id": "7d4975ef"
   },
   "outputs": [],
   "source": [
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = \"C:/Users/ericw/OneDrive/桌面\"\n",
    "os.chdir(path)\n",
    "data = pd.read_csv(\"df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d3bb456",
   "metadata": {
    "id": "4d3bb456",
    "outputId": "9a3e5860-d548-4999-a12b-606b20f4043d"
   },
   "outputs": [],
   "source": [
    "# Adjusting the target variable\n",
    "data['y_binary'] = (data['product_action_pageview_purchase'] >= 1).astype(int)\n",
    "\n",
    "# Identifying feature types\n",
    "dense_features = ['product_action_pageview_detail']\n",
    "sparse_features = ['product_skus_hash', 'day_of_week', 'hour_of_first_interaction', 'hour_of_last_interaction']\n",
    "\n",
    "# Label encode sparse features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "\n",
    "# Normalize dense features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data[dense_features] = scaler.fit_transform(data[dense_features])\n",
    "\n",
    "# Prepare features for DeepCTR\n",
    "X = data[sparse_features + dense_features]\n",
    "y_binary = data['y_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89158680",
   "metadata": {
    "id": "89158680",
    "outputId": "695b708a-934e-4e43-841c-bf38ae714ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3802/3802 - 9s - loss: 0.0214 - accuracy: 0.9917 - val_loss: 0.0172 - val_accuracy: 0.9935\n",
      "Epoch 2/10\n",
      "3802/3802 - 8s - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0174 - val_accuracy: 0.9920\n",
      "Epoch 3/10\n",
      "3802/3802 - 9s - loss: 0.0140 - accuracy: 0.9946 - val_loss: 0.0175 - val_accuracy: 0.9922\n",
      "Epoch 4/10\n",
      "3802/3802 - 9s - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0230 - val_accuracy: 0.9929\n",
      "Epoch 5/10\n",
      "3802/3802 - 9s - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0181 - val_accuracy: 0.9916\n",
      "Epoch 6/10\n",
      "3802/3802 - 8s - loss: 0.0091 - accuracy: 0.9966 - val_loss: 0.0224 - val_accuracy: 0.9929\n",
      "Epoch 7/10\n",
      "3802/3802 - 8s - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0236 - val_accuracy: 0.9929\n",
      "Epoch 8/10\n",
      "3802/3802 - 9s - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0185 - val_accuracy: 0.9926\n",
      "Epoch 9/10\n",
      "3802/3802 - 9s - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.0201 - val_accuracy: 0.9930\n",
      "Epoch 10/10\n",
      "3802/3802 - 8s - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0184 - val_accuracy: 0.9930\n",
      "1189/1189 [==============================] - 1s 1ms/step - loss: 0.0180 - accuracy: 0.9932\n",
      "\n",
      "Test loss: 0.018017780035734177\n",
      "Test accuracy: 0.9932171106338501\n"
     ]
    }
   ],
   "source": [
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the feature columns for DeepFM\n",
    "sparse_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(), embedding_dim=4)\n",
    "                          for i, feat in enumerate(sparse_features)]\n",
    "dense_feature_columns = [DenseFeat(feat, 1,)\n",
    "                         for feat in dense_features]\n",
    "\n",
    "feature_columns = sparse_feature_columns + dense_feature_columns\n",
    "feature_names = get_feature_names(feature_columns)\n",
    "\n",
    "# Convert the dataset into a format that can be fed into DeepFM\n",
    "train_model_input = {name: X_train[name] for name in feature_names}\n",
    "test_model_input = {name: X_test[name] for name in feature_names}\n",
    "\n",
    "# Build, compile, and train the model\n",
    "model = DeepFM(feature_columns, feature_columns, task='binary')\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_model_input, y_train, batch_size=256, epochs=10, verbose=2, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_result = model.evaluate(test_model_input, y_test, batch_size=256)\n",
    "print(\"\\nTest loss:\", eval_result[0])\n",
    "print(\"Test accuracy:\", eval_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5576d08c",
   "metadata": {
    "id": "5576d08c",
    "outputId": "5cdfbb01-33ab-4cf1-c2bd-ae1ec7c04012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[302055    182]\n",
      " [  1881     29]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    302237\n",
      "           1       0.14      0.02      0.03      1910\n",
      "\n",
      "    accuracy                           0.99    304147\n",
      "   macro avg       0.57      0.51      0.51    304147\n",
      "weighted avg       0.99      0.99      0.99    304147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred_probs = model.predict(test_model_input, batch_size=256)\n",
    "# Convert probabilities to binary predictions based on a 0.5 threshold\n",
    "y_pred = (y_pred_probs > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate precision, recall, F1-score, and support\n",
    "clf_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(clf_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd61623f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "Epoch 1/10\n",
      "4753/4753 - 10s - loss: 0.0201 - accuracy: 0.9932\n",
      "Epoch 2/10\n",
      "4753/4753 - 9s - loss: 0.0123 - accuracy: 0.9955\n",
      "Epoch 3/10\n",
      "4753/4753 - 9s - loss: 0.0160 - accuracy: 0.9937\n",
      "Epoch 4/10\n",
      "4753/4753 - 8s - loss: 0.0146 - accuracy: 0.9946\n",
      "Epoch 5/10\n",
      "4753/4753 - 9s - loss: 0.0112 - accuracy: 0.9966\n",
      "Epoch 6/10\n",
      "4753/4753 - 9s - loss: 0.0110 - accuracy: 0.9962\n",
      "Epoch 7/10\n",
      "4753/4753 - 9s - loss: 0.0097 - accuracy: 0.9970\n",
      "Epoch 8/10\n",
      "4753/4753 - 10s - loss: 0.0087 - accuracy: 0.9970\n",
      "Epoch 9/10\n",
      "4753/4753 - 9s - loss: 0.0087 - accuracy: 0.9972\n",
      "Epoch 10/10\n",
      "4753/4753 - 10s - loss: 0.0085 - accuracy: 0.9972\n",
      "Fold 1 ROC-AUC: 0.9919452821142564\n",
      "Training on fold 2...\n",
      "Epoch 1/10\n",
      "4753/4753 - 11s - loss: 0.0206 - accuracy: 0.9931\n",
      "Epoch 2/10\n",
      "4753/4753 - 10s - loss: 0.0127 - accuracy: 0.9957\n",
      "Epoch 3/10\n",
      "4753/4753 - 9s - loss: 0.0099 - accuracy: 0.9970\n",
      "Epoch 4/10\n",
      "4753/4753 - 10s - loss: 0.0089 - accuracy: 0.9971\n",
      "Epoch 5/10\n",
      "4753/4753 - 9s - loss: 0.0094 - accuracy: 0.9968\n",
      "Epoch 6/10\n",
      "4753/4753 - 9s - loss: 0.0091 - accuracy: 0.9969\n",
      "Epoch 7/10\n",
      "4753/4753 - 9s - loss: 0.0093 - accuracy: 0.9969\n",
      "Epoch 8/10\n",
      "4753/4753 - 8s - loss: 0.0091 - accuracy: 0.9971\n",
      "Epoch 9/10\n",
      "4753/4753 - 9s - loss: 0.0084 - accuracy: 0.9973\n",
      "Epoch 10/10\n",
      "4753/4753 - 9s - loss: 0.0080 - accuracy: 0.9974\n",
      "Fold 2 ROC-AUC: 0.9899847129150126\n",
      "Training on fold 3...\n",
      "Epoch 1/10\n",
      "4753/4753 - 10s - loss: 0.0206 - accuracy: 0.9932\n",
      "Epoch 2/10\n",
      "4753/4753 - 11s - loss: 0.0135 - accuracy: 0.9952\n",
      "Epoch 3/10\n",
      "4753/4753 - 10s - loss: 0.0090 - accuracy: 0.9975\n",
      "Epoch 4/10\n",
      "4753/4753 - 10s - loss: 0.0089 - accuracy: 0.9973\n",
      "Epoch 5/10\n",
      "4753/4753 - 11s - loss: 0.0107 - accuracy: 0.9963\n",
      "Epoch 6/10\n",
      "4753/4753 - 9s - loss: 0.0083 - accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "4753/4753 - 9s - loss: 0.0076 - accuracy: 0.9975\n",
      "Epoch 8/10\n",
      "4753/4753 - 9s - loss: 0.0089 - accuracy: 0.9968\n",
      "Epoch 9/10\n",
      "4753/4753 - 9s - loss: 0.0084 - accuracy: 0.9971\n",
      "Epoch 10/10\n",
      "4753/4753 - 9s - loss: 0.0074 - accuracy: 0.9975\n",
      "Fold 3 ROC-AUC: 0.9913278877116193\n",
      "Training on fold 4...\n",
      "Epoch 1/10\n",
      "4753/4753 - 10s - loss: 0.0199 - accuracy: 0.9934\n",
      "Epoch 2/10\n",
      "4753/4753 - 9s - loss: 0.0144 - accuracy: 0.9944\n",
      "Epoch 3/10\n",
      "4753/4753 - 8s - loss: 0.0105 - accuracy: 0.9966\n",
      "Epoch 4/10\n",
      "4753/4753 - 9s - loss: 0.0098 - accuracy: 0.9969\n",
      "Epoch 5/10\n",
      "4753/4753 - 9s - loss: 0.0100 - accuracy: 0.9966\n",
      "Epoch 6/10\n",
      "4753/4753 - 9s - loss: 0.0096 - accuracy: 0.9968\n",
      "Epoch 7/10\n",
      "4753/4753 - 9s - loss: 0.0086 - accuracy: 0.9971\n",
      "Epoch 8/10\n",
      "4753/4753 - 8s - loss: 0.0080 - accuracy: 0.9973\n",
      "Epoch 9/10\n",
      "4753/4753 - 9s - loss: 0.0092 - accuracy: 0.9967\n",
      "Epoch 10/10\n",
      "4753/4753 - 9s - loss: 0.0089 - accuracy: 0.9969\n",
      "Fold 4 ROC-AUC: 0.9901077068287001\n",
      "Training on fold 5...\n",
      "Epoch 1/10\n",
      "4753/4753 - 9s - loss: 0.0199 - accuracy: 0.9934\n",
      "Epoch 2/10\n",
      "4753/4753 - 8s - loss: 0.0143 - accuracy: 0.9945\n",
      "Epoch 3/10\n",
      "4753/4753 - 8s - loss: 0.0105 - accuracy: 0.9966\n",
      "Epoch 4/10\n",
      "4753/4753 - 8s - loss: 0.0100 - accuracy: 0.9969\n",
      "Epoch 5/10\n",
      "4753/4753 - 9s - loss: 0.0100 - accuracy: 0.9968\n",
      "Epoch 6/10\n",
      "4753/4753 - 8s - loss: 0.0096 - accuracy: 0.9968\n",
      "Epoch 7/10\n",
      "4753/4753 - 9s - loss: 0.0092 - accuracy: 0.9969\n",
      "Epoch 8/10\n",
      "4753/4753 - 9s - loss: 0.0084 - accuracy: 0.9971\n",
      "Epoch 9/10\n",
      "4753/4753 - 9s - loss: 0.0087 - accuracy: 0.9970\n",
      "Epoch 10/10\n",
      "4753/4753 - 10s - loss: 0.0089 - accuracy: 0.9968\n",
      "Fold 5 ROC-AUC: 0.9908647373232405\n",
      "Mean ROC-AUC: 0.9908460653785658\n",
      "Standard Deviation of ROC-AUC: 0.0007386312000989813\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store results for each fold\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"Training on fold {fold+1}...\")\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    X_train_fold, y_train_fold = X.iloc[train_idx], y_binary.iloc[train_idx]\n",
    "    X_val_fold, y_val_fold = X.iloc[val_idx], y_binary.iloc[val_idx]\n",
    "    \n",
    "    # Prepare model input\n",
    "    train_model_input = {name: X_train_fold[name] for name in feature_names}\n",
    "    val_model_input = {name: X_val_fold[name] for name in feature_names}\n",
    "    \n",
    "    # Define the DeepFM model\n",
    "    model = DeepFM(feature_columns, feature_columns, task='binary')\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_model_input, y_train_fold, batch_size=256, epochs=10, verbose=2)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_fold = model.predict(val_model_input, batch_size=256)\n",
    "    \n",
    "    # Calculate the ROC-AUC score and append to the list\n",
    "    roc_auc = roc_auc_score(y_val_fold, y_pred_fold)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    print(f\"Fold {fold+1} ROC-AUC: {roc_auc}\")\n",
    "\n",
    "# Calculate the mean and standard deviation of the ROC-AUC scores\n",
    "mean_roc_auc = np.mean(roc_auc_scores)\n",
    "std_dev_roc_auc = np.std(roc_auc_scores)\n",
    "\n",
    "print(f\"Mean ROC-AUC: {mean_roc_auc}\")\n",
    "print(f\"Standard Deviation of ROC-AUC: {std_dev_roc_auc}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
